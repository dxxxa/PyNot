# [Logistic Regression using PyTorch in Python](https://www.thepythoncode.com/article/logistic-regression-using-pytorch)
##
# [[] / []]()
Знакомство
Логистическая регрессия — это вероятностная модель, используемая для описания вероятности дискретных результатов с заданными входными переменными. Несмотря на название, логистическая регрессия является классификационной моделью, а не регрессионной моделью. В двух словах, логистическая регрессия похожа на линейную регрессию, за исключением категоризации.

Он вычисляет вероятность результата с помощью сигмовидной функции. Из-за нелинейного преобразования входной переменной логистическая регрессия не нуждается в линейных корреляциях между входными и выходными переменными.

Этот учебник посвящен разработке модели логистической регрессии для прогнозирования оттока клиентов в PyTorch.

Что такое логистическая регрессия
Хотя название метода включает в себя термин «регрессия», по сути, это контролируемый метод машинного обучения, предназначенный для решения вопросов классификации. Это связано с использованием алгоритмом логистической функции, которая колеблется от 0 до 1.

В результате мы можем использовать логистическую регрессию для прогнозирования вероятности того, что одна переменная объекта (X) принадлежит к определенной категории (Y).

Логистическая регрессия имеет много общего с линейной регрессией, хотя линейная регрессия используется для прогнозирования числовых значений, а не для классификационных вопросов. Обе стратегии используют линию для отображения целевой переменной.

Линейная регрессия помещает линию к данным для прогнозирования новой величины, в то время как логистическая регрессия подходит для оптимального разделения двух классов.

Сигмовидная функция
Чтобы понять, что такое логистическая регрессия и как она работает, необходимо сначала понять сигмовидную функцию и функцию натурального логарифма.

На этом рисунке изображена S-образная кривая переменной для значений x в диапазоне от 0 до 1:

Сигмовидная функцияИсточник: ДепозитФото

На большей части своей области сигмовидная функция имеет значения, которые чрезвычайно близки к 0 или 1. Из-за этого он подходит для использования в задачах двоичной классификации. Взгляните на рисунок ниже, чтобы увидеть, как представлена модель логистической регрессии:

Модель логистической регрессии

Источник: датахакер

Как видите, начнем с вычисления выходных данных линейной функции z. Сигмовидная функция примет этот выход z в качестве входных данных. После этого для вычисляемого z мы сгенерируем предсказание ŷ, которое z определит. Если z является значительным положительным числом, то ŷ будет около единицы.

С другой стороны, если z имеет значительно отрицательное число, ŷ будет близко к нулю.

Следовательно, ŷ всегда будет находиться в диапазоне от 0 до 1. Использование порогового значения 0,5 является простым методом классификации прогноза ŷ.

Если наш прогноз более экстенсивен, чем 0,5, мы предполагаем, что ŷ равен 1.

В противном случае предположим, что ŷ равен нулю. Когда мы применяем логистическую регрессию, наша цель состоит в том, чтобы попытаться вычислить параметры w и b так, чтобы ŷ стал достойной оценкой вероятности ŷ=1.

Описание данных
Набор данных, используемый в этом исследовании, предоставляет информацию об оттоке клиентов на основе различных переменных. Набор данных содержит 2000 строк и 15 функций, которые можно использовать для прогнозирования оттока. Его можно скачать здесь.

Связанные с: Прогнозирование оттока клиентов: полное руководство по Python.

Давайте установим зависимости этого учебника:

$ pip install matplotlib numpy pandas scikit_learn==1.0.2 torch==1.10.1
Для автоматической загрузки набора данных мы можем использовать gdown:

$ pip install --upgrade gdown
$ gdown --id 12vfq3DYFId3bsXuNj_PhsACMzrLTfObs
Давайте начнем:

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from sklearn.utils import resample
from sklearn import preprocessing
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from warnings import filterwarnings
filterwarnings('ignore')
Давайте прочитаем данные, опустим год, customer_id, phone_no столбцы и посмотрим на форму данных:

#reading data
data = pd.read_csv("data_regression.csv")
##The dimension of the data is seen, and the output column is checked to see whether it is continuous or discrete. 
##In this case, the output is discrete, so a classification algorithm should be applied.
data = data.drop(["year", "customer_id", "phone_no"], axis=1)
print(data.shape)         # Lookiing the shape of the data
print(data.columns)       # Looking how many columns data has
data.dtypes  
data.head()
Обработка нулевого значения
Если у нас есть нулевые значения, нам нужно поработать над этим, прежде чем подавать его в нашу модель:

data.isnull().sum()
gender                    24
age                        0
no_of_days_subscribed      0
multi_screen               0
mail_subscribed            0
weekly_mins_watched        0
minimum_daily_mins         0
maximum_daily_mins         0
weekly_max_night_mins      0
videos_watched             0
maximum_days_inactive     28
customer_support_calls     0
churn                     35
dtype: int64
final_data = data.dropna()         # Dropping the null values
Выборка данных
Давайте выберем данные, так как наши данные очень несбалансированы. Апсамплинг и даунсамплинг использовались для классов меньшинств и большинства продукции. Наконец, данные объединяются для дальнейшей обработки:

final_data["churn"].value_counts()       
# let us see how many data is there in each class for deciding the sampling data number
0.0    1665
1.0     253
Name: churn, dtype: int64
Разделение данных
Во-первых, нам нужно разделить фрейм данных на отдельные классы перед выборкой:

data_majority = final_data[final_data['churn']==0] #class 0
data_minority = final_data[final_data['churn']==1] #class 1
#upsampling minority class
data_minority_upsampled = resample(data_minority, replace=True, n_samples=900, random_state=123) 
 #downsampling majority class
data_majority_downsampled = resample(data_majority, replace=False, n_samples=900, random_state=123)
#concanating both upsampled and downsampled class
## Data Concatenation:  Concatenating the dataframe after upsampling and downsampling 
#concanating both upsampled and downsampled class
data2 = pd.concat([data_majority_downsampled, data_minority_upsampled])
## Encoding Catagoricals:  We need to encode the categorical variables before feeding it to the model
data2[['gender', 'multi_screen', 'mail_subscribed']]
#label encoding categorical variables
label_encoder = preprocessing.LabelEncoder()
data2['gender']= label_encoder.fit_transform(data2['gender'])
data2['multi_screen']= label_encoder.fit_transform(data2['multi_screen'])
data2['mail_subscribed']= label_encoder.fit_transform(data2['mail_subscribed'])
## Lets now check again the distribution of the oputut class after sampling
data2["churn"].value_counts()
0.0    900
1.0    900
Name: churn, dtype: int64
В следующем коде мы имеем дело с масштабированием, разделением обучающих и тестовых наборов, а также разделением зависимых и независимых переменных:

#indenpendent variable 
X = data2.iloc[:,:-1]
## This X will be fed to the model to learn params 
#scaling the data
sc = StandardScaler()         # Bringing the mean to 0 and variance to 1, so as to have a non-noisy optimization
X = sc.fit_transform(X)
X = sc.transform(X)
## Keeping the output column in a separate dataframe
data2 = data2.sample(frac=1).reset_index(drop=True) ## Shuffle the data frame and reset index
n_samples, n_features = X.shape ## n_samples is the number of samples and n_features is the number of features
#output column
Y = data2["churn"]
#output column
Y = data2["churn"]
##Data Splitting: 
## The data is processed, so now we can split the data into train and test to train the model with training data and test it later from testing data.
#splitting data into train and test
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42, stratify = Y)
print((y_train == 1).sum())
print((y_train == 0).sum())
630
630
Напечатаем тип поезда и тестового набора:

print(type(X_train))
print(type(X_test))
print(type(y_train.values))
print(type(y_test.values))
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
<class 'numpy.ndarray'>
Преобразуя их в тензоры по мере работы PyTorch, we будет использовать метод torch.from_numpy():

X_train = torch.from_numpy(X_train.astype(np.float32))
X_test = torch.from_numpy(X_test.astype(np.float32))
y_train = torch.from_numpy(y_train.values.astype(np.float32))
y_test = torch.from_numpy(y_test.values.astype(np.float32))
Сделав выходной вектор Y в качестве вектора столбца для умножения матрицы, we выполните это изменение с помощью операции представления, как показано в следующем коде:

y_train = y_train.view(y_train.shape[0], 1)
y_test = y_test.view(y_test.shape[0], 1)
Функция активации
Мы используем функции активации для представления динамического взаимодействия в линейных данных. Здесь мы используем функцию активации сигмовидной кишки. Мы выбрали сигмовидную функцию, так как она ограничит значение от 0 до 1. Функции активации помогают вводить нелинейность в выходной сигнал нейрона, что повышает точность, эффективность вычислений и скорость сходимости.

Функции активации должны быть дифференцируемыми и быстро сходящимися по отношению к весам.

Недостатки сигмовидной кишки:

Исчезающий градиент на стадии обратного распространения нейронной сети (особенно RNN).
Из-за своей экспоненциальной природы он является вычислительно дорогостоящим.
Цитата из этой статьи: «Основной функцией активации, которая широко использовалась, является сигмовидная функция. Однако, когда был представлен линейный блок выпрямителя (ReLU) (Nair & Hinton, 2010), он вскоре стал лучшей заменой сигмовидной функции из-за ее положительного влияния на различные задачи машинного обучения. Хотя использование Sigmoid и работа на более мелких слоях не дает никаких проблем, некоторые проблемы возникают, когда архитектура становится глубже, потому что производные члены, которые меньше 1, будут умножаться друг на друга во много раз, что значения станут меньше. и меньше до тех пор, пока градиент не стремится к нулю, следовательно, исчезает. С другой стороны, если значения больше единицы, происходит обратное, когда умножаемые числа становятся все больше и больше, пока они не будут стремиться к бесконечности и не взорвут градиент. Хорошим решением было бы сохранить значения до 1, чтобы даже когда они умножаются, они не меняются. Это именно то, что делает ReLU: у него есть градиент 1 для положительных входов и 0 для отрицательных.

Построение модели: создание модели логистической регрессии в Pytorch
Ниже приведен код, ответственный за построение модели логистической регрессии в PyTorch:

#logistic regression class
class LogisticRegression(nn.Module):
    def __init__(self, n_input_features):
        super(LogisticRegression, self).__init__()
        self.linear = nn.Linear(n_input_features, 1)
    
    #sigmoid transformation of the input 
    def forward(self, x):
        y_pred = torch.sigmoid(self.linear(x))
        return y_pred
Необходимо объявить слои в модели в методе __init__(). Мы использовали линейные слои, которые задаются с помощью модуля torch.nn. Слою может быть присвоено любое имя, например, self.linear (в нашем случае). Я объявил один линейный слой, потому что это логистическая регрессия.

Синтаксис: torch.nn.Linear(in_features, out_features, bias=True)

Метод forward() отвечает за проведение прямого прохода/распространения. Вход направляется через ранее установленный слой, а выход этого слоя отправляется через функцию активации сигмовидной кишки.

Инициализируем модель:

lr = LogisticRegression(n_features)
Компиляция модели
Определим количество эпох и скорость обучения, которую мы хотим использовать в нашей модели для обучения. Поскольку данные являются двоичными, мы будем использовать двоичную перекрестную энтропию в качестве функции потерь, используемой для оптимизации модели с помощью оптимизатора SGD.

Потери BCE
Мы также будем использовать функцию потерь (ошибок) L для оценки производительности нашего алгоритма. Помните, что функция потерь применяется только к одному обучающему образцу, а наиболее часто используемая функция потерь является квадратичной ошибкой. Однако функция потерь в квадрате ошибки в логистической регрессии не является лучшим вариантом. Он создает задачу оптимизации, которая не является выпуклой, и подход градиентного спуска может не сходиться оптимально. Мы применим потери BCE, чтобы, надеюсь, достичь глобального оптимума.

Потери BCE расшифровываются как двоичные потери кросс-энтропии и часто используются в экземплярах двоичной классификации.

Стоит отметить, что при использовании функции потерь BCE выход узла должен быть между (0–1). Для этого нам нужно будет использовать соответствующий оптимизатор. Мы выбрали SGD, или Stochastic Gradient Descent, регулярно используемый оптимизатор. Другие оптимизаторы включают Адама, Ларса и других.

Вы должны предоставить параметры модели и скорость обучения в качестве входных данных для оптимизатора. SGD выбирает одну точку данных случайным образом из всего набора данных на каждой итерации, чтобы резко свести к минимуму вычисления.

Также обычно выборка небольшого количества точек данных, а не только по одной на каждом шаге (часто называемом мини-пакетным градиентным спуском). Мини-партия пытается сбалансировать эффективность градиентного спуска и скорость SGD.

Скорость обучения
Скорость обучения представляет собой регулируемый гиперпараметр, используемый в обучении нейронных сетей с небольшим положительным значением, часто от 0,0 до 0,1. Более низкие показатели обучения требуют большего количества тренировочных эпох из-за более незначительных изменений в весах с каждым обновлением, в то время как более высокие показатели обучения приводят к быстрым изменениям и требуют меньшего количества тренировочных эпох.

Высокая скорость обучения может привести к тому, что модель слишком быстро сблизится на плохом решении, в то время как низкая скорость обучения может привести к остановке процесса. Используя графики скорости обучения, вы можете изменять скорость обучения по мере прохождения обучения.

Он корректирует скорость обучения на основе предопределенного расписания, такого как время, шаг или экспоненциальный.

Мы можем создать график скорости обучения для обновления скорости обучения на протяжении всего обучения на основе предопределенного правила. Наиболее распространенным планировщиком скорости обучения является ступенчатый затухание, которое снижает скорость обучения на определенный процент после определенного количества тренировочных эпох. Наконец, мы можем сказать, что график скорости обучения является предопределенной структурой для корректировки скорости обучения по эпохам или итерациям по мере обучения.

Ниже приведены две наиболее распространенные стратегии для графиков скорости обучения:

Скорость обучения снижается: Это происходит, когда мы выбираем начальную скорость обучения, а затем постепенно снижаем ее в соответствии с планировщиком.
Постоянная скорость обучения: Как следует из названия, мы устанавливаем скорость обучения и не меняем ее на протяжении всего обучения.
Примечание: Скорость обучения является гиперпараметром, который следует настроить. Вместо того, чтобы использовать постоянную скорость обучения, мы могли бы начать с более высокого значения LR, а затем постепенно уменьшать его после определенного количества раундов. Сначала это позволяет нам быстрее конвергенции снижать риски превышения потерь.

В PyTorch мы можем использовать несколько планировщиков из пакета optim. Вы можете перейти по этой ссылке, чтобы увидеть, как вы можете настроить скорость обучения нейронной сети с помощью PyTorch. Определимся с параметрами, потерями и оптимизатором:

num_epochs = 500                                        
# Traning the model for large number of epochs to see better results  
learning_rate = 0.0001                               
criterion = nn.BCELoss()                                
# We are working on lgistic regression so using Binary Cross Entropy
optimizer = torch.optim.SGD(lr.parameters(), lr=learning_rate)      
# Using ADAM optimizer to find local minima   
Отслеживание тренировочного процесса:

for epoch in range(num_epochs):
    y_pred = lr(X_train)
    loss = criterion(y_pred, y_train)             
    loss.backward()
    optimizer.step()
    optimizer.zero_grad()
    if (epoch+1) % 20 == 0:                                         
        # printing loss values on every 10 epochs to keep track
        print(f'epoch: {epoch+1}, loss = {loss.item():.4f}')
epoch: 20, loss = 0.8447
epoch: 40, loss = 0.8379
epoch: 60, loss = 0.8316
epoch: 80, loss = 0.8257
epoch: 100, loss = 0.8203
epoch: 120, loss = 0.8152
epoch: 140, loss = 0.8106
epoch: 160, loss = 0.8063
epoch: 180, loss = 0.8023
epoch: 200, loss = 0.7986
epoch: 220, loss = 0.7952
epoch: 240, loss = 0.7920
epoch: 260, loss = 0.7891
epoch: 280, loss = 0.7863
epoch: 300, loss = 0.7838
epoch: 320, loss = 0.7815
epoch: 340, loss = 0.7793
epoch: 360, loss = 0.7773
epoch: 380, loss = 0.7755
epoch: 400, loss = 0.7737
epoch: 420, loss = 0.7721
epoch: 440, loss = 0.7706
epoch: 460, loss = 0.7692
epoch: 480, loss = 0.7679
epoch: 500, loss = 0.7667
Здесь происходит первый пас вперед. Далее рассчитывается убыток. Когда вызывается loss.back(), он вычисляет градиент потерь относительно весов (слоя). Затем веса обновляются путем вызова метода optimizer.step(). После этого веса должны быть опорожнены для следующей итерации. Поэтому вызывается метод zero_grad().

Приведенный выше код печатает потерю в каждую 20-ю эпоху.

Производительность модели
Давайте наконец-то увидим точность модели:

with torch.no_grad():
    y_predicted = lr(X_test)
    y_predicted_cls = y_predicted.round()
    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])
    print(f'accuracy: {acc.item():.4f}')
accuracy: 0.5093
Здесь мы должны использовать torch.no_grad(). Цель состоит в том, чтобы опустить градиентное вычисление по весам. Таким образом, все, что я помещаю в этот цикл, не изменит веса и, таким образом, не нарушит процесс обратного распространения.

Мы также можем увидеть точность, отзыв и оценку Формулы-1, используя отчет о классификации:

#classification report
from sklearn.metrics import classification_report
print(classification_report(y_test, y_predicted_cls))
              precision    recall  f1-score   support

         0.0       0.51      0.62      0.56       270
         1.0       0.51      0.40      0.45       270

    accuracy                           0.51       540
   macro avg       0.51      0.51      0.50       540
weighted avg       0.51      0.51      0.50       540
Визуализация матрицы путаницы:

#confusion matrix
from sklearn.metrics import confusion_matrix
confusion_matrix = confusion_matrix(y_test, y_predicted_cls)
print(confusion_matrix)
[[168 102]
 [163 107]]
Заключение
Обратите внимание, что наша модель плохо работает с этим относительно сложным набором данных. Цель этого туториала Вы узнаете, как выполнять логистическую регрессию в PyTorch. Если вы хотите получить лучшую точность и другие метрики, рассмотрите возможность тонкой настройки обучающих гиперпараметров, таких как увеличение числа эпох и скорости обучения или даже добавление еще одного слоя (то есть нейронной сети).

Получите полный код в этой записной книжке Colab.