# [K-Fold Cross Validation using Scikit-Learn in Python](https://www.thepythoncode.com/article/kfold-cross-validation-using-sklearn-in-python)
##
# [[] / []]()
При обучении данных в контролируемом машинном обучении мы ищем не то, насколько хорошо модель работает на обучающих данных, а на новых данных (например, новый клиент, новое преступление, новый образ и т. Д.). Следовательно, наш подход к оценке должен позволить нам изучить, насколько эффективно модели могут предсказывать на основе данных, которые они никогда не видели раньше.

Возможно, вы захотите сдержать часть данных, чтобы проверить гипотезу. Мы называем этот процесс «валидацией» (или удержанием). Наблюдение (признаки и цели) разделены на два набора во время проверки, известные как обучающие и тестовые наборы.

Мы отложили тест, отложенный в сторону, чтобы сохранить иллюзию, что мы никогда его не видели. На следующем этапе мы используем обучающие данные, чтобы научить нашу модель генерировать наиболее точные прогнозы. В качестве заключительного шага мы оцениваем производительность нашей модели, которая обучается на нашем обучающем наборе в нашем тестовом наборе.

В этой стратегии есть некоторые недостатки. В обучающем наборе не будет достаточно данных для модели, чтобы узнать взаимосвязь между входами и выходами для небольших наборов данных, и здесь будет подходить процедура перекрестной проверки k-кратной.

Перекрестная проверка K-fold (KFCV) — это метод, который разделяет данные на k частей, называемых «складками». Затем модель обучается с использованием k - 1 складок, которые интегрируются в единый обучающий набор, а окончательный сгиб используется в качестве тестового набора. Это повторяется k раз, каждый раз с использованием другого сгиба в качестве тестового набора. Затем производительность модели усредняется по k итерациям, чтобы обеспечить общее измерение.

Перекрестная проверка KFoldисточник: scikit-learn.org

Для демонстрации этого учебника убедитесь, что у вас установлен пакет scikit-learn:

$ pip install scikit-learn
Начнем с загрузки необходимых функций и классов:

# Load libraries
from sklearn import datasets
from sklearn import metrics
from sklearn.model_selection import KFold, cross_val_score
from sklearn.pipeline import make_pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import StandardScaler
Мы будем использовать набор данных простых цифр в качестве демонстрации для этого учебника:

# digits dataset loading
digits = datasets.load_digits()
# Create features matrix
features = digits.data
# Create target vector
target = digits.target
Делая наш StandardScaler и модель, в этом случае мы выберем LogisticRegression():

# standardization
standard_scaler = StandardScaler()
# logistic regression creation
logit = LogisticRegression()
Чтобы получить оценку перекрестной проверки KFold в Scikit-learn, можно использовать класс KFold и передать его функции cross_val_score() вместе с конвейером (предварительная обработка и модель) и набором данных:

# pipeline creation for standardization and performing logistic regression
pipeline = make_pipeline(standard_scaler, logit)
# perform k-Fold cross-validation
kf = KFold(n_splits=11, shuffle=True, random_state=2)
# k-fold cross-validation conduction
cv_results = cross_val_score(pipeline, # Pipeline
                             features, # Feature matrix
                             target, # Target vector
                             cv=kf, # Cross-validation technique
                             scoring="accuracy", # Loss function
                             n_jobs=-1) # Use all CPU cores
# View score for all 11 folds
cv_results
array([0.92682927, 0.98170732, 0.95731707, 0.95121951, 0.98159509,
       0.97546012, 0.98159509, 0.98773006, 0.96319018, 0.97546012,
       0.96932515])
Мы использовали k-образную перекрестную проверку с 11 сгибами в нашем решении. Давайте рассчитаем средний балл CV:

# Calculate mean
cv_results.mean()
0.968311727177506
Функция cross_val_score() принимает несколько параметров:

оценщик: объект, используемый для подгонки данных, либо оценщик, либо конвейер, как в нашем случае.
X и y: входные и выходные данные набора данных.
Наш подход к перекрестной валидации определяется параметром cv. K-образный фолд на сегодняшний день является самым популярным, хотя есть и другие, такие как перекрестная проверка leave-one-out, в которой количество сгибов k соответствует количеству наблюдений.
Параметр оценки определяет наш показатель успеха.
Наконец, n_jobs=-1 инструктирует scikit-learn использовать все доступные ядра. Например, если ваш компьютер имеет четыре ядра (что распространено в ноутбуках), scikit-learn будет использовать все четыре ядра одновременно для ускорения процедуры.
Когда вы выполняете KFCV, есть три вещи, которые вы должны иметь в виду:

Поскольку предполагается, что каждое наблюдение было сгенерировано независимо, KFCV начинает с предпосылки, что данные независимы и одинаково распределены (IID). Наборы данных IID следует перетасовывать при назначении складкам. Установите значение shuffle=True в классе KFold для выполнения перетасовки.
Во-вторых, при использовании KFCV для оценки классификатора часто полезно иметь складки, которые содержат почти одинаковую долю данных из каждого целевого класса (стратифицированный k-крат). Если мы хотим выполнить стратифицированную перекрестную проверку KFold в scikit-learn, мы можем просто заменить класс KFold на StratifiedKFold.
При использовании проверяющих наборов или перекрестной проверки крайне важно предварительно обработать данные на основе обучающего набора, а затем применить эти преобразования как к обучающим, так и к тестовым наборам. Причина этого заключается в том, что мы утверждаем, что тестовые данные являются неизвестными данными. Когда мы подгоняем оба наших препроцессора, используя наблюдения из обучающих и тестовых наборов, некоторая информация из тестового набора просачивается в наш обучающий набор. Это правило справедливо для каждого шага предварительной обработки, включая выбор функции. Модуль конвейера в scikit-learn делает это простым при использовании подходов перекрестной проверки. Мы начинаем с создания конвейера, который предварительно обрабатывает данные (например, standard_scaler) перед обучением модели (логистическая регрессия, logit): для каждого этапа предварительной обработки, включая выбор функции.
KFCV является предпочтительным методом для небольших наборов данных по сравнению с разделением поездов/ тестов. Тем не менее, это вычислительно дорого, особенно когда выбранный k высок.
Примечание: Вы можете настроить перекрестную проверку таким образом, чтобы размер сгиба был один (k устанавливается на количество наблюдений в вашем наборе данных). Как обсуждалось в учебнике, этот вид перекрестной проверки называется перекрестной проверкой. Следовательно, многие показатели производительности могут быть агрегированы для правильной оценки точности вашей модели по невидимым данным. Одним из недостатков является то, что это может быть более вычислительно дорогостоящим методом, чем k-кратная перекрестная проверка.

Получите полный демонстрационный код здесь.

Узнайте также: Регуляризация выпадения с помощью PyTorch в Python.